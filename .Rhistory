library(kernlab)
data(spam)
str(spam)
str(trn[,108])
str(trn[,160])
args(train)
library(caret)
args(train)
ls()
str(trn)
?str
str(trn,list.len=200)
pml.names()
pml.name()
names(pml_tst)
names(pml)
ls()
names(trn)
?nearZero
?nearZeroVar
?read.csv
is.na(trn)
?train
spam
str(spam)
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
library(caret)
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
training <- spam[inTrain,]
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
modelFit
?train
modelFit$finalModel
modelFit <- train(training$type ~ .,method="rf",preProcess="pca",data=training)
modelFit
modelFit <- train(type ~ .,method="glm",preProcess="pca",data=training)
?sample
ls()
str(trn)
sample(1:19622,10)
sample(1:19622,100)
? train
#pml_trn
str(trn)
is.na(trn[,18])
sum(is.na(trn[,18]))
sum(is.na(trn[,19]))
sum(is.na(trn[,20]))
sum(is.na(trn[,21]))
colSums(is.na(trn))
nrows(trn)
nrow(trn)
trn[,kurtosis_yaw_belt]
trn[,"kurtosis_yaw_belt"]
summary(trn[,"kurtosis_yaw_belt"])
summary(trn[1:100,"kurtosis_yaw_belt"])
trn[1:100,"kurtosis_yaw_belt"]
str(trn[1:100,"kurtosis_yaw_belt"])
summary(trn[,"kurtosis_roll_belt"])
names(trn)
"skewness" %in% names(trn)
grepl("skewness",names(trn))
trn[,"classe"]
trn[,-"classe"]
trn[,!"classe"]
head(as.numeric(trn))
head(as.numeric(trn[,1:40]))
?rfcv
?train
?rm
rm
rm(list=ls())
?train_control
?varImp
?train
>prcomp
?prcomp
?confusionMatrix
library(caret)
?confusionMatrix
?predict
?varImp
load(caret)
librry(caret)
library(caret)
?varImp
?varImp.randomForest
?cor
?barplot
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
vowel.train[,"y"]<-as.factor(vowel.train[,"y"])
vowel.test[,"y"]<-as.factor(vowel.test[,"y"])
set.seed(33833)
mdlRF<-train(y ~ ., method="rf", data=vowel.train)
library(caret)
mdlRF<-train(y ~ ., method="rf", data=vowel.train)
mdlGBM<-train(y ~ ., method="gbm", data=vowel.train)
mdlGBM<-train(y ~ ., method="gbm", data=vowel.train)
confusionMatrix(vowel.test$y, predict(mdlRF, vowel.test))
confusionMatrix(vowel.test$y, predict(mdlGBM, vowel.test))
?confusionMatrix
confusionMatrix(predict(mdlRF, vowel.test), predict(mdlGBM, vowel.test))
fl<-predict(mdlRF, vowel.test) = predict(mdlGBM, vowel.test)
fl<-predict(mdlRF, vowel.test) == predict(mdlGBM, vowel.test)
head(fl)
confusionMatrix(vowel.test[fl,]$y, predict(mdlGBM, vowel.test[fl,]))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
train(CompressiveStrength ~ ., data=training, method="lasso")
mdLASSO<-train(CompressiveStrength ~ ., data=training, method="lasso")
?plot.enet
plot(mdLASSO)
?enet
mdLASSO$glmnet.fit
str(mdLASSO)
mdLASSO$ModelInfo
mdLASSO$fit
mdLASSO$Fit
mdLASSO<-enet(CompressiveStrength ~ ., data=training, lambda=0)
plot(mdLASSO)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
library(caret)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
str(training)
lasso<-lars(training[2:8,], training[1,], type="lasso", trace=TRUE)
library(lars)
lasso<-lars(training[2:8,], training[1,], type="lasso", trace=TRUE)
lasso<-lars(training[,2:8], training[,1], type="lasso", trace=TRUE)
?lasso
?lars
mdLASSO<-train(CompressiveStrength ~ ., data=training, method="lasso")
mdLASSO
mdLASSO$lambda
plot(mdLASSO)
lasso<-lars(as.matrix(training[,2:8]), training[,1], type="lasso", trace=TRUE)
lasso
plot(lasso)
?lars
coeff(lasso)
coef(lasso)
lasso<-lars(as.matrix(training[,1:8]), training[,9], type="lasso", trace=TRUE)
coef(lasso)
lasso$fit
plot(lasso,plottype="coefficients")
mdRG<-lm(CompressiveStrength ~ ., data=training)
mdRG
?plot.enet
plot(lasso,penalty)
plot(lasso,xvar="penalty")
mdLASSO<-enet(CompressiveStrength ~ ., data=training, lambda=0)
mdLASSO<-enet(CompressiveStrength ~ ., data=training, lambda=0)
?enet
lasso<-enet(as.matrix(training[,1:8]), training[,9], lambda=0, trace=TRUE)
?plot.enet
plot(lasso)
plot(lasso,xvar=penalty)
plot(lasso,xvar="penalty")
plot(lasso,xvar="penalty",use.color=TRUE)
plot(lasso)
plot(lasso,xvar="penalty",use.color=TRUE)
?plot
library(caret)
load(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelFitRF  <- train(diagnosis ~ ., method="rf", data=training)
modelFitGBM  <- train(diagnosis ~ ., method="gbm", data=training)
modelFitLDA  <- train(diagnosis ~ ., method="lda", data=training)
predRF<-predict(modelFitRF, training)
predGBM<-predict(modelFitGBM, training)
predLDA<-predict(modelFitLDA, training)
nt<-data.frame(predRF,predGBM, predLDA,diag=training$diagnosis)
str(nt)
mfRF<-train(diag~.,method="rf",data=nt)
confusionMatrix(testing$diagnosis, predict(mfRF, testing))
str(testing)
predRF<-predict(modelFitRF, testing)
predGBM<-predict(modelFitGBM, testing)
predLDA<-predict(modelFitLDA, testing)
nt<-data.frame(predRF,predGBM, predLDA,diag=testing$diagnosis)
confusionMatrix(testing$diagnosis, predict(mfRF, nt))
confusionMatrix(testing$diagnosis, predict(modelFitRF, testing))
confusionMatrix(testing$diagnosis, predict(modelFitGBM, testing))
confusionMatrix(testing$diagnosis, predict(modelFitLDA, testing))
library(lubridate)
install.packages("lubridate")
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
install.packages("forecast")
bats(training)
?bats
library(forecast)
?bats
md<-bats(training)
str(training)
md<-bats(training[,3])
fc<-forecast(md)
accuracy(fc,testing[,3])
forecast(md)
testing[,3]
?forecast
?accuracy
str(fc)
nrow(testing)
forecast(md,h=235)
forecast(md)
library(forecast)
forecast(md,h=235)
fc<-forecast(md,h=235)
accuracy(fc,testing[,3])
fc[,4]
fc
str(fc)
fc$upper
fc$upper[,2]
r<-(testing[,3] > fc$lower[,2]) & (testing[,3] < fc$upper[,2])
r
sum(r)
len(r)
length(r)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
library(caret)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[ -inTrain,]
set.seed(325)
library(e1071)
svm.model <- svm(CompressiveStrength ~ ., data = training)
str(training)
svm.pred <- predict(svm.model, testing[,-9])
accuracy(svm.pred)
library(forecast)
accuracy(svm.pred)
confusionMatrix(concrete$CompressiveStrength, svm.pred)
confusionMatrix(testing$CompressiveStrength, svm.pred)
str(svm.pred)
str(testing)
confusionMatrix(testing$CompressiveStrength, svm.pred)
table(pred = svm.pred, true = testing[,9])
svm.pred <- predict(svm.model, testing)
confusionMatrix(testing$CompressiveStrength, svm.pred)
table(pred = svm.pred, true = testing[,9])
svm.pred <- predict(svm.model, testing)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
svm.pred <- predict(fit, testing)
accuracy(prediction,testing$CompressiveStrength)
accuracy(svm.pred,testing$CompressiveStrength)
fit <- train(CompressiveStrength ~ ., data = training, method = "svm")
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
?accuracy
rm(list=ls())
setwd("C:/Users/Gary/DataScience/9. Developing Data Products")
ls()
wd()
pwd()
getwd()
install.packages("shiny")
ls)
ls()
library(manipulate)
install_github('slidify', 'ramnathv')
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries',
'ramnathv')
library(slidify)
install_github('slidify', 'ramnathv')
library(slidify)
install_github('ramnathv/slidify')
install_github('ramnathv/rCharts')
install_github('slidify', 'ramnathv')
library(devtools)
.libPaths()
install.packages("devtools")
library(devtools)
install.packages("Rcpp")
library(devtools)
install_github('slidify', 'ramnathv')
install.packages("stringi")
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
install_github('ramnathv/rCharts')
library(shiny)
runApp()
runApp()
runApp()
setwd("C:/Users/Gary/DataScience/9. Developing Data Products/PAProg")
runApp()
library(devtools)
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?textOutput
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?stat_function
setwd("C:/Users/Gary/DataScience/9. Developing Data Products")
setwd("C:/Users/Gary/DataScience/9. Developing Data Products/PAProg")
runApp()
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?scale_color_manual
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("C:/Users/Gary/DataScience/9. Developing Data Products")
setwd("C:/Users/Gary/DataScience/9. Developing Data Products/PAProg")
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("C:/Users/Gary/DataScience/9. Developing Data Products")
setwd("C:/Users/Gary/DataScience/9. Developing Data Products/PAProg")
runApp()
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(shiny)
runApp()
runApp()
runApp()
runApp()
?dataset
?frame
?data.frame
data.frame(cbind(c("Gross","Net")),c(1000,1000),c(1200,1200),c(0.06,0.06))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("C:/Users/Gary/DataScience/9. Developing Data Products")
library(shiny)
runApp()
setwd("C:/Users/Gary/DataScience/9. Developing Data Products/PAProg")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("C:/Users/Gary/DataScience/9. Developing Data Products/PAPitch")
library(slidify)
slidify("index.Rmd")
setwd("C:/Users/Gary/DataScience/9. Developing Data Products")
setwd("C:/Users/Gary/DataScience/9. Developing Data Products/PAProg")
library(shiny)
deployApp()
runApp()
library(rsconnect)
deployApp()
library(shinyapps)
deployApp()
setwd("C:/Users/Gary/DataScience/9. Developing Data Products")
library(slidify)
?publish
setwd("C:/Users/Gary/DataScience/9. Developing Data Products/PAPitch")
publish(title = 'Investment Fund Fee Analyser', 'index.html', host = 'rpubs')
curl-config
curl-config()
find.package("RCurl")
.libPaths
.libPaths("C:/Users/Gary/Documents/R/win-library/3.1/RCurl")
publish(title = 'Investment Fund Fee Analyser', 'index.html', host = 'rpubs')
